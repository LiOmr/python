# Языки прикладного программирования (ЯПП)

## Лабораторная работа №1

### Задание
Разработать на Python (версии 3) программу для вычисления статистических метрик набора данных.

### Входные данные
- csv-файл с данными (russian demographic.csv). (Путь до файла должен указать пользователь)
- Название региона.
- ID колонки, по которой будут найдены статистические метрики.

### Выходные данные (результат)
- Таблица значений по конкретному региону, визуализированная в консоли (выводить все колонки).
- Максимум, минимум, медиана, среднее значение, по данным из выбранной колонки, выведенные в текстовых полях.
- Таблица перцентилей от 0 до 100 с шагом 5.

*Определение:*  
*N-й перцентиль* - это такое число X, что N

Необходимо:
- По выбранной пользователем колонке, с учетом фильтра по региону вывести:
  - Таблицу значений по региону, визуализированная в консоли.
  - Максимум, минимум, медиана, среднее значение, по данным из выбранной колонки, выведенные в текстовых полях.
  - Таблицу перцентилей от 0 до 100 с шагом 5.

Программа должна корректно обрабатывать все виды ошибок и уведомлять об этом пользователя (некорректный входной файл, ошибки данных и т.п.). Программа может иметь консольный или десктопный интерфейс.

—

## Лабораторная работа №2 “Визуализация данных при помощи Python”

### Задание 1
Взять датасет (ссылка, файл Cleaned_ships_data.csv) и в jupyter notebook визуализировать при помощи графиков:
1. 2-D график зависимости средней максимальной загрузки кораблей от длины корабля.
2. Распределение количества кораблей по их типу (ship_name). В целях более корректного отображения диаграммы типы, по которым меньше всего кораблей, можно объединить в один сегмент с названием “Другие”.
3. Гистограмма распределения количества кораблей по годам постройки (built_year).
4. 2-D Гистограмма распределения количества кораблей по годам постройки (built_year) и максимальному весу груза (dwt). Для максимального веса груза сформировать 20 диапазонов, от минимального до максимального значений с равным шагом.
5. Взять датасет (ссылка) и в jupyter notebook визуализировать при помощи графиков:
   - Парную диаграмму (Pairplot) для датасета.
   - Скрипичную диаграмму (Violinplot) с распределением всех четырех характеристик ирисов для каждого вида (для каждой характеристики отдельные “скрипки” для разных видов ирисов).

### Задание 2
Выбрать на kaggle любой датасет, например, один из:
- [Students Performance in Exams](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams)
- [PUBG Stats Dataset](https://www.kaggle.com/datasets/mohammadtalib786/pubg-stats-dataset)
- [Heart Failure Prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)
- [Fortnite Statistics](https://www.kaggle.com/datasets/joebeachcapital/fortnite-statistics)
- [Board Game Data](https://www.kaggle.com/datasets/mrpantherson/board-game-data)
- [Global Grain and Coffee Price History](https://www.kaggle.com/datasets/mabdullahsajid/global-grain-and-coffee-price-history-1973-2023)
- [Data Science Salary 2021 to 2023](https://www.kaggle.com/datasets/harishkumardatalab/data-science-salary-2021-to-2023)
- [Marketing Campaign](https://www.kaggle.com/datasets/shashankshukla123123/marketing-campaign)
- [Customer Segmentation](https://www.kaggle.com/datasets/bhuviranga/customer-segmentation)

Самостоятельно визуализировать данные из датасета, использовав не менее трех различных графиков/гистограмм. Выписать (в виде текстового блока под каждой из диаграмм) что визуализировали и выводы, которые вы сделали на основании графика о данных.

Быть готовым объяснить преподавателю все вышеописанное.

### Общие требования
- На каждом графике должна быть “легенда”.
- Следовать принципам KISS, DRY, YAGNI и т.п.
- Код должен соответствовать code-style соответствующего языка: для Python.



Лабораторная работа №3 “Кластеризация”

Теоретическая часть
Кластерный анализ
Методы кластеризации
Задание на лабораторную работу
Теоретическая часть
Кластерный анализ
Кластеризация (англ. cluster analysis) — задача группировки множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию. 
Задача кластеризации очень часто применяется для первичного анализа статистических данных с целью понять существуют в них группы, объединенные общими критериями. После чего можно уже проводить дальнейшие исследования по формализации этих самых групп и введению классов, что приводит уже к задаче классификации.
Пример кластеризации:

Больше про кластерный анализ можно почитать здесь.
Методы кластеризации
Самыми распространенными методами кластеризации являются:
KMeans (англ. k-means) — самый простой алгоритм кластеризации. Его основная идея - найти центры кластеров (центроиды) и минимизировать суммарное квадратичное отклонение точек кластеров от центров этих кластеров. Центроиды в данном алгоритме по сути выполняют роль центров масс для остальных точек из кластера. Подробно алгоритм расписан здесь.
Иерархическая кластеризация — строит иерархию кластеров. Этот алгоритм начинает работу с того, что каждому экземпляру данных сопоставляется свой собственный кластер. Затем два ближайших кластера объединяются в один и так далее, пока не будет образован один общий кластер. Результат иерархической кластеризации может быть представлен с помощью дендрограммы. Иерархическая кластеризация хуже подходит для кластеризации больших объемов данных в сравнении с методом k-средних. Это объясняется тем, что временная сложность алгоритма линейна для метода k-средних (O(n)) и квадратична для метода иерархической кластеризации (O(n2)). Кроме того в кластеризации при помощи метода k-средних алгоритм начинает построение с произвольного выбора начальных точек, поэтому, результаты, генерируемые при многократном запуске алгоритма, могут отличаться. В то же время в случае иерархической кластеризации результаты воспроизводимы. Из центроидной геометрии построения метода k-средних следует, что метод хорошо работает, когда форма кластеров является гиперсферической (например, круг в 2D или сфера в 3D). Но метод k-средних более чувствителен к зашумленным данным, чем иерархический метод.
Распространения близости (англ. Affinity Propagation) создает кластеры, отправляя сообщения между парами образцов до схождения. Затем набор данных описывается с использованием небольшого количества образцов, которые определяются как наиболее репрезентативные для других образцов. Сообщения, отправляемые между парами, представляют пригодность одного образца быть образцом другого, который обновляется в ответ на значения из других пар. Это обновление происходит итеративно до сходимости, после чего выбираются окончательные образцы и, следовательно, дается окончательная кластеризация.
Средний сдвиг или сдвиг среднего значения (англ. MeanShift) - кластеризация направленная ​​на обнаружение капель в образцах с плавной плотностью. Это алгоритм на основе центроидов, который работает, обновляя кандидатов в центроиды, чтобы они были средними точками в данном регионе. Затем эти кандидаты фильтруются на этапе постобработки, чтобы исключить почти дубликаты и сформировать окончательный набор центроидов. Алгоритм автоматически устанавливает количество кластеров, вместо того, чтобы полагаться на параметр bandwidth, который определяет размер области для поиска. Этот параметр можно установить вручную, но можно оценить с помощью предоставленной estimate_bandwidth функции, которая вызывается, если полоса пропускания не задана. Алгоритм не отличается высокой масштабируемостью, так как он требует многократного поиска ближайшего соседа во время выполнения алгоритма. Алгоритм гарантированно сходится, однако алгоритм прекратит итерацию, когда изменение центроидов будет небольшим.
DBSCAN (Density-Based Spatial Clustering of Applications with Noise, плотностной алгоритм пространственной кластеризации с присутствием шума) – популярный алгоритм кластеризации, используемый в анализе данных в качестве одной из замен метода k-средних. Метод не требует предварительных предположений о числе кластеров, но нужно настроить два других параметра: eps и min_samples. Данные параметры – это соответственно максимальное расстояние между соседними точками и минимальное число точек в окрестности (количество соседей), когда можно говорить, что эти экземпляры данных образуют один кластер. В scikit-learn есть соответствующие значения параметров по умолчанию, но, как правило, их приходится настраивать самостоятельно. Подробнее об алгоритме здесь в этой статье.

Задание на лабораторную работу
Написать программу на языке Python 3, выполняющую кластеризацию входной двумерной выборки на 15 кластеров несколькими методами. Результатом каждой кластеризации должна быть картинка графика.
Файл с входной выборкой: http://cs.joensuu.fi/sipu/datasets/s1.txt
Выполнять кластеризацию необходимо с помощью модуля scikit-learn, а строить графики с помощью matplotlib или seaborn.
Методы кластеризации, которыми необходимо воспользоваться в программе:
KMeans 
AffinityPropagation
MeanShift 
AgglomerativeClustering
DBSCAN 
Сравнить получившиеся результаты кластеризации и сделать выводы о применимости методов к различным видам кластерных данных. Также необходимо уметь отвечать на вопросы о преимуществах и недостатках каждого рассмотренного метода.
Общие требования
На каждом графике должна быть “легенда” 
Следовать принципам KISS, DRY, YAGNI и т.п.
Код должен соответствовать code-style соответствующего языка: для Python


### Полезные ссылки:
1. [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html)
2. [Kaggle Datasets](https://www.kaggle.com/datasets)



Языки прикладного программирования
Лабораторная работа №4 
“Интерполяция, аппроксимация, линейная регрессия”

Теоретическая часть
Интерполяция
Аппроксимация
Линейная регрессия
Полезные ссылки
Задание на лабораторную работу
Теоретическая часть
Интерполяция
Интерполяция - это способ нахождения промежуточных значений величины по имеющемуся дискретному набору известных значений. Интерполяция использует значения некоторой функции, заданные в ряде точек, чтобы предсказать значения функции между ними.
Графически задача интерполирования заключается в том, чтобы построить такую интерполирующую функцию, которая бы проходила через все узлы интерполирования. Линейная интерполяция – простейший и часто используемый вид интерполяции. Она состоит в том, что заданные точки соединяются прямолинейными отрезками, а функцию y(x) можно приближенно представить в виде ломаной.
Аппроксимация
Аппроксимация – замена одних математических объектов другими, в том или ином смысле близкими к исходным. При интерполировании, интерполирующая функция строго проходит через узловые точки таблицы вследствие того, что количество коэффициентов в интерполирующей функции равно количеству табличных значений.
Аппроксимация – метод приближения, при котором для нахождения дополнительных значений, отличных от табличных данных, приближенная функция проходит не через узлы интерполяции, а между ними (рис. 1).

Рисунок 1 – интерполирующая и аппроксимирующая функции
Линейная регрессия
Линейная регрессия — модель зависимости переменной x от одной или нескольких других переменных (факторов, регрессоров, независимых переменных) с линейной функцией зависимости. Цель линейной регрессии — поиск линии, которая наилучшим образом соответствует этим точкам (рис. 2).

Рисунок 2 – Пример построения линии регрессии	
Полезные ссылки
Также по данным понятиям, методам и примерам их использования можно более подробно почитать в следующих источниках:
Интерполяция:
https://habr.com/ru/post/264191/
https://help.fsight.ru/ru/mergedProjects/lib/03_transformations/uimodelling_interpolation.htm
https://portal.tpu.ru/SHARED/m/MBB/uchebnaya_rabota/Model/Tab/Interp_app.pdf
http://aco.ifmo.ru/el_books/numerical_methods/lectures/glava3.html


Регрессия:
https://pythobyte.com/linear-regression-in-python-with-scikit-learn-bc1b4512/
https://habr.com/ru/post/514818/
http://statistica.ru/theory/osnovy-lineynoy-regressii/
https://blog.skillfactory.ru/glossary/linejnaya-regressiya/
https://neurohive.io/ru/osnovy-data-science/linejnaja-regressija/
Задание на лабораторную работу
     	Необходимо реализовать программу на языке Python 3, позволяющую на основании некоторой выборки данных, давать предсказания по вводимым с клавиатуры значениям входного параметра. Решать данную задачу необходимо методом линейной регрессии. Реализацию метода можно взять из библиотеки scikit. В качестве входных данных, можно использовать один из следующих датасетов (или любой другой подходящий, но более интересный):
https://www.kaggle.com/dwdkills/russian-demography
https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston
https://www.kaggle.com/tunguz/country-regional-and-world-gdp
Результат - визуализировать.
В качестве альтернативы, вместо линейной регрессии можно решить задачу интерполяции несколькими методами (линейная, квадратичная, кубическая, сплайны), также визуализировать результаты. В качестве входных данных задаётся не выборка, а математическая функция в коде (можно сделать и ввод с клавиатуры, например с использованием функции eval) с шагом вычисления точек для исходных данных. При вводе значений параметра с клавиатуры выдавать интерполированное значение функции. Добавить проверку на то, что искомая точка лежит внутри известных интервалов. Для оценки интерполяции, также выдавать результат сравнения результата интерполирования с значением заданной функции в данной точке. Методы интерполяции также могут быть взяты из библиотеки.
     	В качестве дополнительного задания, можно написать собственную реализацию линейной, кусочно-квадратичной или квадратичной интерполяции (или другой, более сложный алгоритм) на дополнительные баллы.
Общие требования
На каждом графике должна быть “легенда” 
Следовать принципам KISS, DRY, YAGNI и т.п.
Код должен соответствовать code-style соответствующего языка: для Python

—

